exp_name: shared_ppo_vacl_entity_progression
from_checkpoint: null
seed: 123
num_gpus: 1
num_workers: 13
num_envs_per_worker: 5
num_eval_workers: 1
eval_interval: 20
eval_episodes: 5

stop_timesteps: 60000000

# env configs
env: mpe
scenario: curriculum_simple_spread_po  # curriculum_push_ball
env_config:
  num_agent_candidates: [2, 4, 8, 16]
  num_observable_agents: 1
  episode_length: 25

# algorithm configs
gamma: 0.99
gae_lambda: 1.0
kl_coeff: 0.5
num_sgd_iter: 10
lr: 0.0001
entropy_coeff: 0.0
clip_param: 0.3
vf_clip_param: 10.0

# curriculum configs
teacher: vacl_ep_mpe
teacher_config:
  # VACL Entity Progression
  threshold_next: 0.9  # convergence threshold
  decay_interval: 30  # smooth the task prop of old and new num_agents
  ratio_next: 0.1  # prop of new num_agents, and increments this value after each decay_interval
